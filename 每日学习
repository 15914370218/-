## 2022-03-12
## TCP 和 UDP 的区别：11
    TCP：传输控制协议
    UDP：用户数据报协议
    TCP面向连接（可靠），UDP面向无连接（不可靠）（发送数据之前不需要进行连接）
    TCP堵塞控制，UDP没有堵塞控制，网络阻塞不会隐藏发送放的发送速度（实时会议）
        流量控制：控制发送方流量，（老师讲课（发送方）如果讲很多知识，那么学生消化不了，这时候需要减少发送方的传输速度），避免接收方崩了
            怎么解决的：通过滑动窗口来进行流量控制，说白了就是发送数据的时候先通过一个窗口（接收窗口---高速发送方，接收方有多少的缓存空间可以用）
                      tcp是全双工通信，接收方也可以是发送方，每一方都维护着对方的接收窗口  
        拥塞控制：由于ip网络自身拥堵，导致发送方的发送能力被遏制住了，由于网络被拥堵了，那么发送方的速度要控制一下，不然更堵
            阻塞窗口：网络超时，堵了的话就慢慢发送 ，发送的数据量少，判断回复的ack的时间来判断网络的拥堵程度        
    TCP只能一对一，UDP一对多，多对一，多对多

    索引：
    索引是一种数据结构，类似于字典，数据都是存储在磁盘中的，要想检索某条数据，需要把数据从磁盘加载到内存中，然后再进行检索，如果没有索引，需要把大量无用的数据加载到内存，有了索引，就不需要了，直接可以根据目录查找对应的，并且底层使用b+tree 又因为b+tree大部分都是2-4层，所以只需要2-4次的磁盘io就可以了。
    索引的分类：
    BTREE索引：底层采用B+tree的数据结构，B+tree是b树加叶子节点顺序访问指针（为了方便叶子节点的区间搜索），btree的平衡性
    hash索引：根据索引列的值进行hash计算得到的，不支持排序，因为hash是无序的，不支持范围查找，不支持模糊查找，性能不稳定（如果hash冲突很麻烦）
    全文索引：用于char，varchar，text字段
    RTREE索引： 这个索引仅支持geometry数据类型，优势在于范围查找
    最左匹配原则: 用于组合索引，遇到范围查询（>,<between,like)后面的字段不会用到索引，
    索引覆盖：就是查找的数据直接可以在二级索引找到，不需要进行回表的操作
    前缀索引：对文本或者字符串前几个字符建立索引，这样索引的长度短，更高效率，但是要保证区别率，
    设计原则：区别率的数据，短索引，不是越多越好，索引需要维护的（页分裂，页合并）
    索引失效：组合索引，like，列类型是字符（没有使用引号，隐式类型转换），判断普通索引列不等于某个值，对普通索引列进行运算，查询条件使用or连接（普通索引失效）
    索引的页分裂：一开始的时候只有一个根页（1号），当根页的数据存满了之后，再次插入数据的时候，先整出来一个空页（2号），然后把根页的数据转移到新页（2号）中，根页此时没有数据，
        然后再进行页分裂的操作，再创建一个新页（3号），把刚才的（2号）页一半的数据（向下取整），转移到（3号）中，然后再将（3号）页与父页（1号）进行关联，2号与3号用项链指针关联，这就是一次分页
        ps：如果涉及到根页，必须是新建一个新的，把所有的根页的数据转移过去，而页分裂只有一半
    索引优化：注意组合索引，少用like，普通索引列or之后的用不到索引，索引的长度，索引列进行运算，union会生成临时表（分为内存临时表，磁盘临时表（内存放不下就会存入磁盘，此时效率很低，union all就不会）
    
    Object的方法：toString(),equals(),hashCode(),clone(),getClass(),wait(),notify(),finalize(),
    
    反射：动态获取类的信息，以及动态调用对象的方法，应用场景：JDBC，Eclipse，IDEA动态提示对象的属性和方法，Spring AOP，Web服务器利用反射调用Servlet的service放啊
    
    工作中OOM的排查：查看服务器的运行日志，使用jstat查看监控JVM的内存和gc情况，使用MAt工具导入dump文件，分析大对象的占用情况
    
    Redis的哨兵模式：哨兵模是一个特殊的模式，是一个独立的进程，可以单独运行，原理：哨兵通过每秒发送ping命令，监控redis服务器的响应，客户端连接redis的时候，也是先连接哨兵，哨兵会高速客户端
        Redis主节点的地址，然后客户端再连接这个主节点，主节点宕机的时候（一个哨兵检测到，会被标记为主观下线，然后多个哨兵检测到就被标记为客观下线），哨兵检测到，然后会从从节点总选举新的主节点，然后通过发布订阅模式通知其他的从服务器
        
## 2022-03-14     
    CAS：Java的Unsafe类里面的一个方法 全称是CompareAndSwap比较与交换，主要是多线程环境下对共享变量的原子性操作
    有几个参数，某个对象，某个对象的某个属性的地址偏移量，期望值，修改值 这个过程是原子的
    如果CPU多核的时候会有一个Lock的汇编指令 对缓存或者总线加锁 来保证原子性
    应用场景：Atomic里面 ，AQS里面
    CAS（自旋锁）（无锁，利用cpu的cas指令，原子操作）：比较和交换，更新前判断数据是否别的线程修改，如果没有则更新，
        取出期望值（主内存） i= 0（期望值）
        计算目标值：最终计算的结果 i =1
        调用CAS（强一致性）指令，获取出i的当前值（主内存的值）跟期望值（0）进行比较，如果相等，就进行替换，否则回到第一步
    CAS缺点：ABA问题（有新的api，提供版本号 AtomicStampedReference），内存消耗   （CAS失败，不断重试，自旋）比较少的减少线程上下文切换，synchroznied比较多，jdk有longadder（弱一致性，有延迟的，会有误差），分段计算，最后总和 
    Unsafe:私有类
    LongAdder：内部有一个类似于分段锁的概念
    线程上下文切换：一个线程的时间片用完，或者因自身原因被迫暂停运行，这个时候，另外一个线程倍操作系统选中该，占用处理器 这就是    
    Synchronized:
        Synchronized分别修饰一个静态方法和一个实例方法，是否线程安全：不安全，静态锁的是class对象，实例所的是当前对象
        Synchronized原理：javac编译时，会在代码块前后加上monitorenter和monitorexit，当执行到monitorenter就会尝试去获取锁
            碰到异常会释放锁，因为它会隐式添加一个try,catch,finally finally中有monitorexit指令
        monitorenter如何尝试获取锁，锁究竟是什么? 每个对象都有一个monitor与之关联，如果monitor被持有后，它便处于锁定状态，程序碰到
            monitorenter 会尝试获取对象所对应的monitor的所有权（即尝试获取对象的锁）
        无锁（001）
        偏向锁（101）默认延迟4s启动（JVM启动之后，4s之后偏向锁才会启作用）jdk15取消，如果明确知道某个资源会有很多线程竞争，就  没有必要启动偏向锁，因为升级为偏向锁，还得
            进行锁撤销，再变为轻量级锁，为什么4s，因为jvm启动时候，会有很多线程竞争锁
        为社么有自旋锁还要有重量级锁：自选需要消耗cpu资源，锁的时间越长，自旋的线程越多，cpu消耗更多，更容易cpu飙高
            重量级锁有等待队列，拿不到锁的线程会进行等待队列，不消耗cpu资源
        偏向锁---》轻量级锁---》重量级锁
        偏向锁---》重量级锁（重度竞争，耗时过长wait等）
        普通对象---》轻量级锁---重量级锁
        批量重偏向
        批量撤销：在多线程环境下，使用偏向锁不好，会有一个偏向撤销的计数器，当达到某个阈值时，不会变为偏向锁
        Moniter：
            重量级锁：waitSet+EntryList（阻塞队列）+Owner（指向持有锁的线程）
            优化：对象由：对象头，实例数据，对齐填充构成，对象头里面存了Mark Word，Mark Word存了对象自身的一些运行信息比如：
                hashcode，GC分代年龄，锁状态标志，持有的锁
                锁升级的流程：无锁-->偏向锁-->轻量级锁-->锁自旋-->重量级锁
                    偏向锁： 依赖当前线程id  jdk15禁用了
                    重量级锁：依赖monitor
                    轻量级锁：依赖锁记录：lock-record
                    首先会判断Mark Word里面是否有当前线程id，若有则处于偏向锁，若无锁则尝试用CAS将Mark Word替换为线程id，若成功则偏向锁设置成功，失败则有竞争要升级为
                    轻量级锁
                    轻量级锁：开始会创建锁记录（Lock record）对象，然后我们每个线程的栈帧都会包含一个锁记录的结构，内部可以用来存储锁定对象的mark Word
                    然后让所记录中object reference指向锁对象，并尝试用CAS替换object的markword，将mark word的值存入锁记录
                    如果CAS替换成功，对象头中存储了锁记录地址和状态00
                    如果失败，有两种情况：如果是其它线程已经持有了改Object的轻量级锁，这时表明有竞争，准备升级重量级锁
        
## 2022-03-15               
    线程池如何知道一个线程的任务执行完
    
## 2022-03-17
    为什么需要线程池：线程的服用，并且如果频繁创建线程，线程需要从新建到就绪到运行状态，流程有点多（成本大），如果是线程池 就一直在运行中
            核心就是复用，减少就绪状态到运行状态的切换
    项目中哪些地方使用线程池：禁止自己new thread 如果接口被人知道了，会导致线程过多，cpu飙升
    线程池的作用：降低资源消耗，提高响应速度，线程的可管理性，还有自定义的功能
    线程池的创建方式：jdk原生的方式Executors提供的四个：单例，可缓存，可定时线程池，不会使用这个 因为底层是无界队列缓存任务的，会发生线程池溢出
            Executors基于ThreadPoolExecutor 底层基于无限队列 会导致任务过多内存溢出
    线程池如何实现复用：1.提前创建号固定的而线程一直在运行状态：每个子线程里面的run方法死循环
                    2.提交的任务缓存到一个并发队列集合钟，交给我们正在运行的线程
                    3.正在运行的线程从队列中获取任务执行
    线程池参数：核心线程数，最大线程数，非核心线程数的存活时间，拒绝策略
    ThreadPoolExecutor底层实现原理：先创建核心线程数，之后的任务放入阻塞队列，然后阻塞队列满了，创建额外的线程，最大线程满了，直接拒绝
    拒绝策略：丢弃任务，忽视，踢出一开始的任务，自定义处理方式
    
## 2022-03-19
    ReenLock    
    悲观锁：mysql中基于行锁
    乐观锁：基于版本号
    每个线程的ThreadLocalMap可以存放n多个不同的ThreadLocal对象
    每个ThreadLocal对象只能缓存一个变量值
    ThreadLocalMap是一个内部类有点类似于map 里面是数组 每一个数组的元素是Entry类型 set方法的时候最终 new Entry（threadLocal,value）加入ThreadLocalMap
        ThreadLocalMap类里面的Entry是弱引用 弱引用只有在jvm不足的时候才会释放
        
    ThreadLocal：线程的局部变量，空间换时间 相对来说ThreadLocal比Synchronized有效 线程隔离，传递数据 
        new ThreadLocal()new在哪里，那么就是往new的那个线程里面的ThreadLocalmap添加数据 因为set的时候会获取当前线程       
    public static void main(String[] args) throws  Exception{
        ThreadLocal<String> stringThreadLocal = new ThreadLocal<>();
        stringThreadLocal.set("linyukun");
        stringThreadLocal.set("linyukun2");
        ThreadLocal<String> stringThreadLoca2 = new ThreadLocal<>();
        stringThreadLoca2.set("linyukun3");
        stringThreadLoca2.set("linyukun4");
        System.out.println(stringThreadLocal.get());
        主线程的ThreadhLocalMap里面塞了两个东西
    ThreadLocal的底层原理：每个线程有自己的独立的ThreadLocalMap对象，
    ThreadLocal的内存泄露：
        如果ThreadLocalMap里面的Entry的key是强引用，那么即使外部的引用变为null，但是由于还有ThreadLocalMap的entry里面的key引用着它，那么堆空间的ThreadLocal对象也不会被释放
        如果改为弱引用：当gc的时候，内存不足的时候，gc会把弱引用的移除掉，这也是解决内存泄漏的问题，并且set的时候也会删除以前为null的引用 线程挂了，停了，那么里面的ThreadLocalmap也会清除
        但是这样仍然会有问题；仍然会有内存泄露问题，最好手动删除，因为如果你这个线程的周期很长，那么ThreadLocaMap的生命周期很长
        内存泄漏：没办法释放内存
        如何解决：1.每次set的时候回去判断，如果存在null就会删除
                2.自己调用remove
                3.对象设为弱引用
                4.代码逻辑使用完ThreadLoca，都要调用remove（），即使清理，尽量不要使用全局ThreadLoca       
        手动调用ThreadLocal.remove方法
    ThreadLocal使用场景：获取httprequest，tomcat接受请求，spring事务模板类，模板方法 aop拦截
        把用户数据存入threadLocal，然后控制层，service层都可以获取到
    强软弱虚：
    强引用：生成的对象在堆空间 ，变量名在栈空间
        Object o1 =new Object();
        Object o2 = o1;
        o1 = null;
        此时 o2输出还是有值的
        就算出现OOM也不会被回收
    软引用：系统内存不足时，才会被gc回收
    弱引用：不管jvm的内存空间够不够用，都会被垃圾回收器回收
    虚：
    
## 2022-03-20 AQS底层实现
    CPU乱序执行：有些操作比较久，那么可以同时执行其他的事情，但是有些时候不能乱序执行（Happends-Before规则）
    工作内存对应cpu高速缓存，对应jvm的虚拟机栈
    线程的工作内存与主内存同步时机：只有线程的工作内存失效的时候，工作内存才会重新加载主内存的变量 工作内存失效的时机：
        1.线程中释放锁（所以加锁就能解决）
        2.线程切换时（应该是线程状态的切换 cpu线程上下文切换 (暂时理解为状态切换）
        3.CPU有空闲时间(释放CPU资源)（比如线程休眠，IO操作(BIO),new Socket(); new Thread 调用System下面的方法也会）（io操作包括System.out.println()）
                
    Volatile工作中基本用不到
        作用：1.保证多线程的时候对共享变量的可见性 2.通过内存屏障防止多个指令之间的重排序
        可见性问题的原因：CPU里面用到了三级缓存去解决cpu的运算效率和内存效率的问题，缓存一致性问题，导致线程的可见性问题 
        重排序：程序的编写顺序和执行顺序不一致，从而导致多线程下面的可见性问题 这个是性能优化来的，CPU层面
        工作原理：变量使用volatile修饰变量，那么JVM虚拟机会自动去增加一个#lock的汇编指令，这个指令会根据不同的cpu型号，增加不同的总线锁或者缓存锁
            总线锁：锁住的是CPU的前端总线，所以一个时刻只能有一个线程和内存通信
            缓存锁：对总线锁的优化，只针对三级缓存中的目标数据进行加锁，缓存所使用MESI的缓存一致性协议来实现的
            硬件-写屏障指令：storeBarrier  写屏障指令之前的代码必须在写屏障指令之后的代码 先执行完 保证指令不重排序
            硬件-读屏障指令：loadBarrier就是让各个内存的高速缓冲区的数据失效 保证可见性
            前面先执行，后面再执行 类似于load 屏障load 屏障：就像一个墙 可以实现可见性和禁止重排序 
            java-:loadloadBarriers        
            java-：storesotreBarriers
            java- loadsotreBarriers 
            java- sotreloadBarriers
     
     JVM解决指令重排序是定义了Happends-Before规则（8种）:可见性规则 前一个操作的结果对后续操作时可见的 并且保证了无论怎么排，某些操作必须在某些操作前面 有点像禁止重排序 天生的规则 
        不用背 只是JVM规范 实现是用内存屏障实现的（前后不能调换，有一个屏障，堵死了）
        1.程序顺序规则（as-if-serial），单线程中，
        2.监视器锁规则：对一个锁的解锁 Happends-Before 于后续对这个锁的加锁 synchronized
        3.volatile变量规则：对一个Volatile域的写 Happends-Before对于任意后续对这个volatile域的读
        4.传递性规则：如果 A Happends-Before B ,且 B Happends-Before C 那么 A Happends-Before C
        5.start规则：父线程启动子线程之前的所有操作，对于子线程来说都是可见的
        6.join规则：线程的join
        7.线程终止
        8.线程中断
    final域：普通变量会被重排序再构造函数之外 ，但是final修饰的就不会
        

    Unsafe默认提供cas操作 Unsafe 应用于AQS和ReentrantLock（底层是CAS） CountDownLatch（门suan，等多少个线程结束之后才执行）(可以保证哪个线程先执行）
    Lock（ReentrantLock 重入锁，里面的state会累加 这个跟LockSupport也是，不需要可以使用时间的）的底层实现：AQS+Cas+LockSupport锁实现 
    Synchronized和lock哪个好？个人建议Synchronized
    Lock锁的升级过程需要自己实现
    Synchronized的锁过程直接在c++层面处理好 保证有序性（只有一个线程进来），不保证 原子性
    CurrentHashmap1.7用lock锁,1.8用synchronized
    LockSupport:（也可以用于控制哪个线程先执行
        park停车（线程阻塞）（CAS不会线程阻塞） 必须要线程先起来 在unpark       
        LockSupport 可以叫醒某个指定的线程
        连续多次调用unpark只会生产一个许可，一个线程创建出来，然后运行，此时没有许可的，所以unpark可以再park之前运行
        支持主线程先调用unpark，线程a再调用park而不被阻塞 这个跟wait和notify有很大的区别
        LockSupport不需要再同步代码块中，所以线程间不需要维护一个共享的同步对象，实现了线程之间的解耦
        unpark函数可以先于park调用，不需要担心线程间的执行的先后顺序：可以这样理解，直接把unpark给那个线程，当那个线程park的时候因为有了unpark标识，所以直接通过
        比watie和notify更为准确，以及语义的明确   wait不能先于notify执行 notify不释放锁（关键） notify和wait必须保证某一个线程先运行
      
    AQS：AbstractQueuedSynchronizer (队列同步器),包含双向队列，一个volatile修饰的state JUC下面很多包都是基于AQS
        wait和notify跟AQS差距很远
        因为AQS里面如果state为0的时候 ，等待的方法没有效果的，直接通过，只有加锁了之后，这个等待的方法才会有效果
        
        原理： 状态0表示 锁没有被其他线程持有  1表示已经被别的线程持有了 ，被别的线程持有之后 ，会把等待的线程放入双向队列（FIFO）中
        当某一个线程执行完之后，唤醒那个阻塞的双向链表里面的线程
    
## 2022-03-22   
    Nginx：
        先去寻找本地host.com 然后再去运营商寻找对印度个nds
        Nginx本身也是一个web服务器，类似于tomcat 基于C语言开发
        功能：负载均衡，反向代理，微服务网关入库，静态资源服务器，安全策略，熔断，防止ddos攻击，限流
        反向代理：保护服务器的安全 
        正向代理：聚合视频平台 聚合视频会员        
        nginx默认80端口 
        负载均衡：ip哈希，url哈希，轮询，权重，按响应时间
        集群的问题：session一致性，分布式任务调度重复，分布式日志问题（elk+kafka日志收集）
        上游服务器就是服务器
        linux查看进程 ps aux | grep 'nginx'
        nginx启动之后有两个进程（master 进程，work进程） 跟redis差不多 ，只有一个master进程 多个worker进程
        nginx中的root表示nginx的根目录  如果是别的目录 需要使用alias  并且后面的那个配置要用/结尾
        nginx的servre相当于访问的域名
        nginx的proxy-pass后面的/记得需要添加 会替换location里面的东西
        跨域问题： 后台的服务之前做一个网关（由网关进行分发）
                1.服务端设置响应允许跨域 response.setHeader("Access-Control-Allow-Origin","*") 需要在B服务设置这个 ，调用服务方不可以设置，被调用方服务可以设置
                2.使用jsonp实现解决 缺点：只能发送get请求；ajax的dataType设置为jsonp 再加 jsonp:"jsonpCallback",jsonpCallback:"callback" b项目返回callback字样 相当于在地址栏拼接
                3.基于Nginx实现统一接口的域名和端口号：api.mayikt.com/mayikt-a a项目 api.mayikt.com/mayikt-b b项目
                4.使用微服务中的网关解决跨域问题
                5.使用Httpclient实现转发和nginx反向代理的原理一样；没啥用
                
                
## 2022-03-24
        lvs:心跳技术
            1.如何保证服务正常7*24小时运行
            2.nginx如果挂了，如何保证服务高可用
            3.基于nginx+lvs+keepalived搭建高可用
                lvs(Linux virtual server)Linux的虚拟服务 进行ip的虚拟
                keepalived是一个lvs的辅助包，提供监听机制 ，可以实现nginx的一主一备 主挂了，会自动监听（ping）命令，然后重启
        
## 2022-03-27                                    
        Springboot的@Async @EnableAsync 异步注解
            多线程封装的
            @Async会结合aop去进行拦截  最好封装成一个类去操作 不然有可能失效的
            @Async结合线程池
        mysql与Redis的的数据不同步的问题：不可能强一致性 短暂的数据延迟 分布式的时候不可能强一致性的啊            
            1.采用mq定于mysql binlog日志文件增量同步到Redis中（最终一致性） 基于阿里的canal
            我们会把数据存储在数据库和reids，那么就有可能同时更新数据库和redis，并且这个过程有先后顺序，所以就会有一致性问题
            无论先更新数据库，再删除缓存，还是先删除缓存再更新数据，都很难保证后面的操作是否失败
            之后出现一种延时双删除的策略，缺点，需要延时，不适合频繁修改数据，并且延时时间是一个预估值，不能确保mysql和redis数据再这个时间段内都实时同步
                并且需要保证延迟的时间要大于一次写操作的时间，如果小于，那么请求1清除了，请求2还没有写入，又被清除了，这样循环下去 
                极端情况下如果上述中(延迟N秒)的时间要大于一次写操作的时间，一般为3-5秒。
                       原因：如果延迟时间小于写入redis的时间，会导致请求1清除了缓存，但是请求2缓存还未写入的尴尬。。。
                       https://www.it610.com/article/1306087917600411648.htm
            
            
        
        redis的持久化策略：aof（增量同步）（ererysec会放入缓冲区，再放入文件中，always没有用到缓冲区的），rdb（默认）（定时）（全量）
        RDB原理：fork子进程，生成一个临时文件 然后覆盖，缺点fork进程的时候如果很庞大，会阻塞redis 工作交给子进程完成
        AOF：追加文件：如果参数是always 那么每个write和save都会由主线程完成，导致redis阻塞 ，如果参数是everysec，会有缓冲区，由子线程完成，不会阻塞主线程
            如果aof太庞大，会进行重写的 重写是通过fork子进程的，新的命令会添加到这个缓存中
        
        
        ACID的D持久性：redolog和undolog属于存储引擎层 不属于mysql层
                     通过redolog  数据库---》redolog---》磁盘（io瓶颈）（有时间才把redo中的数据记录到磁盘
                            为什么需要有redolog 因为redolog是顺序写的 比往磁盘里面找到对应的数据要强 例子：饭店赊账的本子，和当天的记录本
                            redolog用于机器重启的时候恢复数据的
                     二阶段提交（保证binlog和redolog数据一致）：不是事务那个  更新数据，先写入redolog(prepare状态）----》binlog----》redolog（commit状态）
                                这样有好处 如果redolog处于（prepare状态），然后机器奔溃了，启动的时候，检查 对应的redolog去查找一下对应的binlog是否存在，如果没有就不需要管了，如果有就需要把prepare变为commit           
               隔离性：MVCC：无锁，前提理解：快照读（读取的是旧的版本的数据）（最普通的select），当前读（读取最新的数据）（update,insert，delter，select……lock in share mode,select…… for update，串行化)                           
                           多版本并发控制，用于解决数据库的并发读写的问题 读读 读写（存在脏读，幻读，不可重复读）） 写写（丢失更新问题）
                           实现原理：隐藏字段（BD_TRX_ID,DB_ROLL_PTR,DB_ROW_ID
                           只要查看的数据的数据对应的事务id再 readview里面的活跃事务或者最大尚未分配的下一个事务id要大 那么就是查看不了的
                           
                           undolog不会无限追加，后台会有一个purge的线程去清除undolog 回滚日志
                           readview：读视图，是事务在进行快照读操作的时候生成的数据视图（trx_list（活跃事务id，up_limit_id（当前列表中最小事务id的值，low_limit_id（系统尚未分配的下一个事务id
                                     可见性算法：readview里面的活跃事务或者最大尚未分配的下一个事务id要大 那么就是查看不了的
                                     readview和隔离级别没有关系，只是单纯的的可见性判断
                           不能解决幻读，为什么 因为幻读可能基于（update，insert的时候会读取最新的readview视图）
                                        怎么解决：查询的时候 加上 for update 那样别的事务就读取不到了 通过加锁的方式可以解决
show variableds like '%innodb_status_output_locks%'
set   GLOBAL            innodb_status_output_locks = 1
SHOW ENGINE INNODB STATUS;                                                                 
 
                                                  
# 2022-03-28
        redis单线程：底层采用一个线程维护多个不同的客户端io操作 epoll支队活跃的socket连接实现主动回调      
        rediskey自动过期机制：客户端监听redis的key失效：需要再redis的配置文件配置notify-keyspace-events Ex
            然后配置RedisKeyExpirationiListener

# 2022-04-01
        redis的
        canal
   
# 2022-04-03
        零拷贝技术：直接在内核态将磁盘的文件传输到网卡 不再经过用户态
                java里面有fileChannel使用零拷贝  平常的inputstream就是用户态到内核态
        浮点数：浮点可以变动的数
        分布式共识（少数服从多数）算法Raft：每个从有一个自己随机的选举超时时间，如果选巨超时时间到了，就会发起申请，我要成为候选人，如果超过一半的数，那么就可以成为领导人
                之后每次从的访问的时候，如果领导人有反应，就会刷新自己的超时时间，如果刚好有某一瞬间，有几个节点获得选票，那么就要重新随机了（这几个节点）
                如果由于网络问题，出现了两个领导者，所以节点数一定要奇数，不然偶数，两个领导 ，有可能没有办法写数据
                领导的要超过一半的子返回数据才可以算这个操作成功，网络恢复之后，弱的领导会遵循强的领导。自己变为从，同步强的领导的信息
                类似于redis的哨兵选举机制
        redis的主从好处：如果主关了，从可以顶上，从（被选举人），那么需要有群众（哨兵--基数），判断哪个从做领导
                超过半数的哨兵 说主下线才是客观下线， 否则都是主观下线，然后此时哨兵中 需要选巨一个哨兵老大，由哨兵老大判断哪一个从节点变为主                                     
        哨兵模式：自动故障转移
        代理模式：说白了，直接调用目标类的东西，变为通过代理类调用目标类的东西（间接调用）
                用于：权限校验，打印日志：
                静态代理：程序运行之前，对目标类编写了代理类的代码，编译代理类，说白了编译的时候生成代理类的文件
                动态代理：不需要事先进行代理类的编写，在运行的时候，通过反射自动生成代理对象
                    JDK动态代理：代理类实现INvocationHandler接口，然后往代理类里面注入一个目标类对象的变量
                                Proxy.newProxyInstance()，代理类和目标类要实现相同的接口，如果没有接口就不能代理了
                                通过反射创建代理对象，然后创建的对象放入缓存，下一次使用就不需要放入缓存了，有一个问题，如果热更新了可能就有问题了
                                每次调用方法都是通过java的反射调用的    
                    Cglib动态代理：jdk动态代理的问题：生成的代理类继承了Proxy 那么就丢失了目标类父类的信息了（目标类如果继承了某个父类，重写了方法
                            那么就不能代理了），代理类继承目标类就完事了，这就是cglib
                                并且cglib不是通过反射调用目标类的方法的，是通过fase class的方式（直接调用目标类的方法）编号和方法做成一个字典
                                通过super调用  

## 2022-04-06
        2PC两阶段提交协议：将整个事务分为两个阶段，P是指准备阶段，C是指提交阶段
        准备阶段：事务管理器每个参与者发送Prepare消息，每个数据库参与者在本地执行事务，并写本地的undo/redo日志，此时事务酶有提交
        提交阶段：如果事务管理器收到了参与者的执行失败或者超时消息时，直接给每个参与者发送回滚消息，否则发送提交消息，参与者根据事务管理器指令进行提交或者回滚操作
        Seata：是一个分布式事务
            AT模式：默认，可以解决80%以上的问题，两阶段提交协议的演变
                一阶段：在一阶段钟，Seata会拦截“业务SQL”，首先解析SQL语义，找到要更新的业务数据，在数据更新前，保存在“undolog”
                    然后执行“业务SQL”更新数据，更新之后保存“redolog“，最后生成锁，这些操作都是本地数据库事务中完成，这样保证一阶段的原子性
                二阶段：二阶段比较简单，负责整体的回滚和提交，如果之前的一阶段有本地事务没有通过，那么执行全局回滚，回滚用到的就是一阶段的”undolog”
                    通过回滚记录生成反向更新SQL并执行，已完成分支事物的回滚，事务完成后删除所有资源和日志                                          
            TC：事务协调者：Seata的服务端 
            TM：事务管理器：全局事务的发起者
            RM：资源管理器：参与者
        
## 网络安全
    DDOS攻击：分布式拒绝服务攻击（Distributed Denied of Service）  发起流量攻击
        三种方式：1.带宽攻击：（压入大文件，大图片）控死带宽
                2.协议攻击：
                3.应用攻击：类似于压力测试
        防御技术：构建黑白名单（不同的ip很难处理），高仿代理（钞能力），动态带宽（钞能力），CDN内容分发（图片，js，流量进行分发了），网关限流和拒绝（某个api接口）nginx网关                   
    
    
        
        
        
## 项目介绍
    商城：根据不同的时间段展示不同的价格 （定时任务实现）（改为redis）
            
            
## 设计模式 需要有springboot基础
    策略模式（strategy）：客户端使用上下文获取具体策略，具体策略上下文 
        传递Ali_pay就获取对应的class类 在通过java的多态机制 不需要写if了 可以定义枚举类（或者读取数据库字段（存储全类名，支付方式表（id，全类名））
        策略+工厂+反射 分类
    责任链模式（带有Handler）：主要用作一些校验 api接口限流，黑名单，用户会话，参数过滤 以上几个环节必须都要通过 相当于游戏的第一关，第二关
        第三关，第四关，相当于oa系统里面的请假流程 相当于双向链表 一个类一个类嵌套  过滤器 可以把数据封装到数据库 
        使用：java的过滤器 ：参数过滤，session过滤，表单过滤，隐藏过滤，检查请求头过滤
    外观模式，门面模式，包装模式Facade）：收集日志，修改订单状态，调用积分接口，调用消息接口，流水 其实主要是对自身逻辑进行拆分
            系统模块之间容易维护 用于一个项目里面业务分类，防止一个类里面的代码太多了       很多小的一系列操作 功能拆分   
    装饰器模式：java的 InputStream  FilterInputStream ByteArrayInputStream
               FilterInputStream 下面的 LineNumberInputStream CheckedInputStream
               
               
     正向代理：代理的是客户端 对客户端负责 科学上网（访问外网） 加速访问（游戏加速器） 缓存数据 授权访问，隐藏访问者
     反向代理：代理的是服务端 对服务端负责 保护服务器（不让服务器被外人知道） 负载均衡
     
            
## 网络：
    cpu执行完一个线程的代码的时候，会把对应的线程的哪一行代码和寄存器 保存起来 每个线程的运行到哪一行代码，以及寄存器放到对应的一个进程里面         
    线程切换：把上一个线程的内容保存下来
    线程越多，cpu为了保证所有的线程都要执行 需要频繁切换 时间很多浪费在切换的上面
    一个程序：多少个线程核实.根据线程的等待时间 和运行时间进行比较
    三级缓存：一颗CPU里面有两个核（运算核心） 每个核有自己的pc，l1,l2，寄存器，ALU（计算单元）   l3在每一颗cpu中被两个核共享 运算核心用来执行线程
    缓存行（一整块数据 64个字节 （1个字节8位）64*8bit）：程序局部性原理（空间局部性，时间局部性）当cpu的核访问数据的时候，把这个数据的一整块数据读取回来
         空间局部性：访问一个数据的时候，通常很快就会访问第二个数据
    缓存一致性：因为有了缓存行，所以需要保证缓存数据的一致性 每个CPU的厂商都不一样
        大部分都是MESI，这个是缓存一致性协议的一种a
    
    
    
    
## shell脚本
    sed：stream editor流式编辑器，逐行处理 sed基本都是玩正则
        查：-r 表示使用正则， -n不会默认输出 -p会把替换的行打印出来    

## 杂记：    
    雪花算法：注意时间回拨的问题（手动调时间）（或者多个服务器之间时间同步，有可能id重复
    布隆过滤器（blom Filter）：判断数据（经过级次hash）是否存在，，如果二进制上面是1，那么就可能存在或者不存在，让如果0，那么一定不存在，少概率误判
        如何减少误判：1.增加二进制位的长度 
                    2.增加hash的次数
        商品删除了怎么办：  1.定时重构布隆过滤器，
                        2.计数布隆过滤器（某一位被多少个元素引用了） 
    为什么禁止IP直连：如果更换mysql服务器，那么需要重新搭配（并且生产的时候也很麻烦，所有的代码都需要改）
        解决： 1.DNS域名解析服务器，ip地址的迁移很快捷，但是没有故障发现和转移，一个域名可以配置多个ip，但是这多个ip只能轮询
              2。加入注册中心：Nacos，Eureka Consul  
    负载均衡器：轮询，权重，iphash，urlhash，fair（三方）  
                      
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
       
